{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC4zWOuFr8Fz"
   },
   "source": [
    "# Check out PyTorch StyleGAN Encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5JbiEpACtiRZ",
    "outputId": "72b11e1e-e629-4869-a0bc-501a57d80a5c"
   },
   "outputs": [],
   "source": [
    "# !rm -r pytorch_stylegan_encoder\n",
    "!git clone --recurse-submodules https://github.com/ficinator/pytorch_stylegan_encoder.git\n",
    "%cd pytorch_stylegan_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9BgFAjsVq6mw"
   },
   "outputs": [],
   "source": [
    "from InterFaceGAN.models.stylegan_generator import StyleGANGenerator\n",
    "from models.latent_optimizer import PostSynthesisProcessing\n",
    "from models.image_to_latent import ImageToLatent, ImageLatentDataset\n",
    "from models.losses import LogCoshLoss\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qVZSXWp_hbnI",
    "outputId": "fda28642-3d0a-42c8-bb98-6dd7ca18ee2b"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8zr4fwr2kIL"
   },
   "source": [
    "# Generate Images\n",
    "\n",
    "* download the pretrained model\n",
    "* use it to generate 50k faces with corresponding dlatents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hzZkaxZ2sC4"
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/qyv37eaobnow7fu/stylegan_ffhq.pth?dl=1 -O InterFaceGAN/models/pretrain/stylegan_ffhq.pth --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGzYEIGY5yRc",
    "outputId": "7bbf8319-61e4-4a7c-a38b-e29c43f28250"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'stylegan_ffhq'\n",
    "DRIVE_DIR = Path('../drive/MyDrive/ML')\n",
    "# DATA_DIR = DRIVE_DIR/'data'/MODEL_NAME\n",
    "DATA_DIR = Path('data')/MODEL_NAME\n",
    "NUM_IMAGES = 50000\n",
    "!rm -r $DATA_DIR\n",
    "!python InterFaceGAN/generate_data.py -m $MODEL_NAME -o $DATA_DIR -n $NUM_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCNPlQfEq6my"
   },
   "source": [
    "# Create Dataloaders\n",
    "Using a 50,000 image dataset. Generated with the generated_data.py script at https://github.com/ShenYujun/InterFaceGAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5sesYOw2q6m0"
   },
   "outputs": [],
   "source": [
    "augments = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "image_size = 256\n",
    "num_images_train = int(.8 * NUM_IMAGES)\n",
    "\n",
    "filenames = sorted(glob(str(DATA_DIR/'*.jpg')))\n",
    "\n",
    "train_filenames = filenames[:num_images_train]\n",
    "validation_filenames = filenames[num_images_train:]\n",
    "\n",
    "dlatents = np.load(DATA_DIR/'wp.npy')\n",
    "\n",
    "train_dlatents = dlatents[:num_images_train]\n",
    "validation_dlatents = dlatents[num_images_train:]\n",
    "\n",
    "train_dataset = ImageLatentDataset(train_filenames, train_dlatents, transforms=augments)\n",
    "validation_dataset = ImageLatentDataset(validation_filenames, validation_dlatents, transforms=augments)\n",
    "\n",
    "train_generator = torch.utils.data.DataLoader(train_dataset, batch_size=32)\n",
    "validation_generator = torch.utils.data.DataLoader(validation_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84mrgDakq6m1"
   },
   "source": [
    "# Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WTN9zTH4q6m2",
    "outputId": "cc482c82-014c-42df-81be-c7e558d04a7f"
   },
   "outputs": [],
   "source": [
    "image_to_latent = ImageToLatent(image_size).cuda()\n",
    "optimizer = torch.optim.Adam(image_to_latent.parameters())\n",
    "criterion = LogCoshLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JYEl0U3q6m3"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "vr2mCVIDq6m4",
    "outputId": "2b8e03fc-c753-4a29-e2f7-4032b3044579"
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "validation_loss = 0.0\n",
    "\n",
    "progress_bar = tqdm(range(epochs))\n",
    "for epoch in progress_bar:    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    image_to_latent.train()\n",
    "    for i, (images, latents) in enumerate(train_generator, 1):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images, latents = images.cuda(), latents.cuda()\n",
    "        pred_latents = image_to_latent(images)\n",
    "        loss = criterion(pred_latents, latents)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_description(\"Step: {0}, Loss: {1:4f}, Validation Loss: {2:4f}\".format(i, running_loss / i, validation_loss))\n",
    "    \n",
    "    validation_loss = 0.0\n",
    "    \n",
    "    image_to_latent.eval()\n",
    "    for i, (images, latents) in enumerate(validation_generator, 1):\n",
    "        with torch.no_grad():\n",
    "            images, latents = images.cuda(), latents.cuda()\n",
    "            pred_latents = image_to_latent(images)\n",
    "            loss =  criterion(pred_latents, latents)\n",
    "            \n",
    "            validation_loss += loss.item()\n",
    "    \n",
    "    validation_loss /= i\n",
    "    progress_bar.set_description(\"Step: {0}, Loss: {1:4f}, Validation Loss: {2:4f}\".format(i, running_loss / i, validation_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPJSNc1Aq6m5"
   },
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pstvaTVZq6m6"
   },
   "outputs": [],
   "source": [
    "model_dir = DRIVE_DIR/'models/image2latent'\n",
    "torch.save(image_to_latent.state_dict(), model_dir/f\"{datetime.utcnow().strftime('%Y-%m-%d_%H:%M')}_{NUM_IMAGES}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iktmy2Fq6m7"
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCWREdO_q6m8"
   },
   "outputs": [],
   "source": [
    "image_to_latent = ImageToLatent(image_size).cuda()\n",
    "image_to_latent.load_state_dict(torch.load(model_dir/'2022-11-17_13:17_1000.pt'))\n",
    "image_to_latent.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbTFPSQdq6m-"
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0RUv4wE0q6m-"
   },
   "outputs": [],
   "source": [
    "def normalized_to_normal_image(image):\n",
    "    mean=torch.tensor([0.485, 0.456, 0.406]).view(-1,1,1).float()\n",
    "    std=torch.tensor([0.229, 0.224, 0.225]).view(-1,1,1).float()\n",
    "    \n",
    "    image = image.detach().cpu()\n",
    "    \n",
    "    image *= std\n",
    "    image += mean\n",
    "    image *= 255\n",
    "    \n",
    "    image = image.numpy()[0]\n",
    "    image = np.transpose(image, (1,2,0))\n",
    "    return image.astype(np.uint8)\n",
    "\n",
    "\n",
    "num_test_images = 5\n",
    "images = [validation_dataset[i][0].unsqueeze(0).cuda() for i in range(num_test_images)]\n",
    "normal_images = list(map(normalized_to_normal_image, images))\n",
    "\n",
    "pred_dlatents = map(image_to_latent, images)\n",
    "\n",
    "synthesizer = StyleGANGenerator(MODEL_NAME).model.synthesis\n",
    "post_processing = PostSynthesisProcessing()\n",
    "post_process = lambda image: post_processing(image).detach().cpu().numpy().astype(np.uint8)[0]\n",
    "\n",
    "pred_images = map(synthesizer, pred_dlatents)\n",
    "pred_images = map(post_process, pred_images)\n",
    "pred_images = list(map(lambda image: np.transpose(image, (1,2,0)), pred_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xrw20M_fq6m_"
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(25,10))\n",
    "columns = len(normal_images)\n",
    "rows = 2\n",
    "\n",
    "axis = []\n",
    "\n",
    "for i in range(columns):\n",
    "    axis.append(figure.add_subplot(rows, columns, i + 1))\n",
    "    axis[-1].set_title(\"Reference Image\")\n",
    "    plt.imshow(normal_images[i])\n",
    "\n",
    "for i in range(columns, columns*rows):\n",
    "    axis.append(figure.add_subplot(rows, columns, i + 1))\n",
    "    axis[-1].set_title(\"Generated With Predicted Latents\")\n",
    "    plt.imshow(pred_images[i - columns])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1K4unTXENrX"
   },
   "outputs": [],
   "source": [
    "!zip -q $DATA_DIR $DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eal_sAmDEQVo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
